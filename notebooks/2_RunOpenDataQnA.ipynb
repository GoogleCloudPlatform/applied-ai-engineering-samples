{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; align-items: left;\">\n",
    "    <a href=\"https://sites.google.com/corp/google.com/genai-solutions/home?authuser=0\">\n",
    "        <img src=\"https://storage.googleapis.com/miscfilespublic/Linkedin%20Banner%20%E2%80%93%202.png\" style=\"margin-right\">\n",
    "    </a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2024 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# **Open Data QnA**\n",
    "\n",
    "---\n",
    "\n",
    "This notebook assumes you have already Setup Vector Store and Variables are assigned in Config.ini file\n",
    "\n",
    "\n",
    "The notebook covers the following steps: \n",
    "\n",
    "> 1. Take user question and generate sql in the dialect corresponding to data source\n",
    "\n",
    "> 2. Execute the sql query and retreive the data\n",
    "\n",
    "> 3. Generate natural language respose and charts to display\n",
    "\n",
    "> 4. Clean Up resources\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“’ Using this interactive notebook\n",
    "\n",
    "Click the **run** icons â–¶ï¸  of each section within this notebook.\n",
    "\n",
    "> ðŸ’¡ Alternatively, you can run the currently selected cell with `Ctrl + Enter` (or `âŒ˜ + Enter` on a Mac).\n",
    "\n",
    "> âš ï¸ **To avoid any errors**, wait for each section to finish in their order before clicking the next â€œrunâ€ icon.\n",
    "\n",
    "This sample must be connected to a **Google Cloud project**, but nothing else is needed other than your Google Cloud project.\n",
    "\n",
    "You can use an existing project. Alternatively, you can create a new Cloud project [with cloud credits for free.](https://cloud.google.com/free/docs/gcp-free-tier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸš§ **0. Pre-requisites**\n",
    "\n",
    "Make sure that you have completed the intial setup process using [1_SetUpVectorStore.ipynb](1_SetUpVectorStore.ipynb). If the 1_SetUpVectorStore notebook has been run successfully, the following are set up:\n",
    "* GCP project and all the required IAM permissions\n",
    "\n",
    "* Environment to run the solution\n",
    "\n",
    "* Data source and Vector store for the solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âš™ï¸ **1. Retreive Configuration Parameters**\n",
    "The notebook will load all the configuration parameters from the `config.ini` file in the root directory. \n",
    "Most of these parameters were set in the initial notebook `1_SetUpVectorStore.ipynb` and save to the 'config.ini file.\n",
    "Use the below cells to retrieve these values and specify additional ones required for this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "sys.path.append(module_path)\n",
    "\n",
    "import configparser\n",
    "config = configparser.ConfigParser()\n",
    "config.read(module_path+'/config.ini')\n",
    "\n",
    "PROJECT_ID = config['GCP']['PROJECT_ID']\n",
    "DATA_SOURCE = config['CONFIG']['DATA_SOURCE']\n",
    "VECTOR_STORE = config['CONFIG']['VECTOR_STORE']\n",
    "PG_SCHEMA = config['PGCLOUDSQL']['PG_SCHEMA']\n",
    "PG_DATABASE = config['PGCLOUDSQL']['PG_DATABASE']\n",
    "PG_USER = config['PGCLOUDSQL']['PG_USER']\n",
    "PG_REGION = config['PGCLOUDSQL']['PG_REGION'] \n",
    "PG_INSTANCE = config['PGCLOUDSQL']['PG_INSTANCE'] \n",
    "PG_PASSWORD = config['PGCLOUDSQL']['PG_PASSWORD']\n",
    "BQ_OPENDATAQNA_DATASET_NAME = config['BIGQUERY']['BQ_OPENDATAQNA_DATASET_NAME']\n",
    "BQ_LOG_TABLE_NAME = config['BIGQUERY']['BQ_LOG_TABLE_NAME'] \n",
    "BQ_DATASET_REGION = config['BIGQUERY']['BQ_DATASET_REGION']\n",
    "BQ_DATASET_NAME = config['BIGQUERY']['BQ_DATASET_NAME']\n",
    "BQ_TABLE_LIST = config['BIGQUERY']['BQ_TABLE_LIST']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ” **2. Authenticate and Connect to Google Cloud Project**\n",
    "Authenticate to Google Cloud as the IAM user logged into this notebook in order to access your Google Cloud Project.\n",
    "\n",
    "You can do this within Google Colab or using the Application Default Credentials in the Google Cloud CLI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Colab Auth\"\"\" \n",
    "# from google.colab import auth\n",
    "# auth.authenticate_user()\n",
    "\n",
    "\n",
    "\"\"\"Google CLI Auth\"\"\"\n",
    "# !gcloud auth application-default login\n",
    "\n",
    "\n",
    "import google.auth\n",
    "credentials, project_id = google.auth.default()\n",
    "\n",
    "# Configure gcloud.\n",
    "!gcloud config set project {PROJECT_ID}\n",
    "print(f'Project has been set to {PROJECT_ID}')\n",
    "!gcloud auth application-default set-quota-project {PROJECT_ID}\n",
    "\n",
    "import os\n",
    "os.environ['GOOGLE_CLOUD_QUOTA_PROJECT']=PROJECT_ID\n",
    "os.environ['GOOGLE_CLOUD_PROJECT']=PROJECT_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## â–¶ï¸ **3. Run the Open Data QnA Pipeline**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ”— **3A. Connect to Datasource, Vector Source and Vertex AI**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the USER_DATABASE based on data source\n",
    "from dbconnectors import pgconnector, bqconnector\n",
    "if DATA_SOURCE=='bigquery':\n",
    "    USER_DATABASE=BQ_DATASET_NAME \n",
    "    src_connector = bqconnector\n",
    "else: \n",
    "    USER_DATABASE=PG_SCHEMA\n",
    "    src_connector = pgconnector\n",
    "\n",
    "print(\"Source selected is : \"+ str(DATA_SOURCE) + \"\\nSchema or Dataset Name is : \"+ str(USER_DATABASE))\n",
    "print(\"Vector Store selected is : \"+ str(VECTOR_STORE))\n",
    "\n",
    "\n",
    "# Set the vector store paramaters\n",
    "if VECTOR_STORE=='bigquery-vector':\n",
    "    region=BQ_DATASET_REGION\n",
    "    vector_connector = bqconnector\n",
    "    call_await = False\n",
    "\n",
    "else:\n",
    "    region=PG_REGION\n",
    "    vector_connector = pgconnector\n",
    "    call_await=True\n",
    "\n",
    "\n",
    "num_table_matches = 5\n",
    "num_column_matches = 10\n",
    "similarity_threshold = 0.3\n",
    "num_sql_matches=3\n",
    "\n",
    "\n",
    "RUN_DEBUGGER = True \n",
    "EXECUTE_FINAL_SQL = True \n",
    "\n",
    "from google.api_core.exceptions import NotFound\n",
    "from google.cloud import aiplatform\n",
    "import vertexai\n",
    "\n",
    "from agents import EmbedderAgent, BuildSQLAgent, DebugSQLAgent, ValidateSQLAgent, ResponseAgent, VisualizeAgent\n",
    "\n",
    "\n",
    "embedder = EmbedderAgent('vertex') \n",
    "\n",
    "SQLBuilder = BuildSQLAgent('gemini-1.0-pro')\n",
    "SQLChecker = ValidateSQLAgent('gemini-1.0-pro')\n",
    "SQLDebugger = DebugSQLAgent('gemini-1.0-pro')\n",
    "Responder = ResponseAgent('gemini-1.0-pro')\n",
    "Visualize = VisualizeAgent ()\n",
    "\n",
    "found_in_vector = 'N'\n",
    "final_sql='Not Generated Yet'\n",
    "\n",
    "vertexai.init(project=PROJECT_ID, location=region)\n",
    "aiplatform.init(project=PROJECT_ID, location=region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  â“ **3B. Ask your Natural Language Question**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\033[1mData Source:- \"+ DATA_SOURCE)\n",
    "print(\"Vector Store:- \"+ VECTOR_STORE)\n",
    "print(\"Schema:- \"+USER_DATABASE)\n",
    "    \n",
    "# Suggested question for 'fda_food' dataset: \"What are the top 5 cities with highest recalls?\"\n",
    "#  Suggested question for 'google_dei' dataset: \"How many asian men were part of the leadership workforce in 2021?\"\n",
    "\n",
    "prompt_for_question = \"Please enter your question for source :\" + DATA_SOURCE + \" and database : \" + USER_DATABASE\n",
    "# user_question = input(prompt_for_question) #Uncomment if you want to ask question yourself\n",
    "user_question = '' # Or Enter Question here\n",
    "\n",
    "print(\"Asked Question:- \"+user_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the embedding of the user's input question \n",
    "embedded_question = embedder.create(user_question)\n",
    "\n",
    "# Reset AUDIT_TEXT\n",
    "AUDIT_TEXT = ''\n",
    "\n",
    "AUDIT_TEXT = AUDIT_TEXT + \"\\nUser Question : \" + str(user_question) + \"\\nUser Database : \" + str(USER_DATABASE)\n",
    "process_step = \"\\n\\nGet Exact Match: \"\n",
    "# Look for exact matches in known questions \n",
    "exact_sql_history = vector_connector.getExactMatches(user_question) \n",
    "\n",
    "if exact_sql_history is not None:\n",
    "    found_in_vector = 'Y' \n",
    "    final_sql = exact_sql_history\n",
    "    invalid_response = False\n",
    "    AUDIT_TEXT = AUDIT_TEXT + \"\\nExact match has been found! Going to retreive the SQL query from cache and serve!\"\n",
    "\n",
    "\n",
    "else:\n",
    "    # No exact match found. Proceed looking for similar entries in db \n",
    "    AUDIT_TEXT = AUDIT_TEXT +  process_step + \"\\nNo exact match found in query cache, retreiving revelant schema and known good queries for few shot examples using similarity search....\"\n",
    "    process_step = \"\\n\\nGet Similar Match: \"\n",
    "    if call_await:\n",
    "        similar_sql = await vector_connector.getSimilarMatches('example', USER_DATABASE, embedded_question, num_sql_matches, similarity_threshold)\n",
    "    else:\n",
    "        similar_sql = vector_connector.getSimilarMatches('example', USER_DATABASE, embedded_question, num_sql_matches, similarity_threshold)\n",
    "\n",
    "    process_step = \"\\n\\nGet Table and Column Schema: \"\n",
    "    # Retrieve matching tables and columns\n",
    "    if call_await: \n",
    "        table_matches =  await vector_connector.getSimilarMatches('table', USER_DATABASE, embedded_question, num_table_matches, similarity_threshold)\n",
    "        column_matches =  await vector_connector.getSimilarMatches('column', USER_DATABASE, embedded_question, num_column_matches, similarity_threshold)\n",
    "    else:\n",
    "        table_matches =  vector_connector.getSimilarMatches('table', USER_DATABASE, embedded_question, num_table_matches, similarity_threshold)\n",
    "        column_matches =  vector_connector.getSimilarMatches('column', USER_DATABASE, embedded_question, num_column_matches, similarity_threshold)\n",
    "\n",
    "    AUDIT_TEXT = AUDIT_TEXT +  process_step + \"\\nRetrieved Similar Known Good Queries, Table Schema and Column Schema: \\n\" + '\\nRetrieved Tables: \\n' + str(table_matches) + '\\n\\nRetrieved Columns: \\n' + str(column_matches) + '\\n\\nRetrieved Known Good Queries: \\n' + str(similar_sql)\n",
    "    # If similar table and column schemas found: \n",
    "    if len(table_matches.replace('Schema(values):','').replace(' ','')) > 0 or len(column_matches.replace('Column name(type):','').replace(' ','')) > 0 :\n",
    "\n",
    "        # GENERATE SQL\n",
    "        process_step = \"\\n\\nBuild SQL: \"\n",
    "        generated_sql = SQLBuilder.build_sql(DATA_SOURCE,user_question,table_matches,column_matches,similar_sql)\n",
    "        final_sql=generated_sql\n",
    "        AUDIT_TEXT = AUDIT_TEXT + process_step +  \"\\nGenerated SQL : \" + str(generated_sql)\n",
    "        \n",
    "        if 'unrelated_answer' in generated_sql :\n",
    "            invalid_response=True\n",
    "\n",
    "        # If agent assessment is valid, proceed with checks  \n",
    "        else:\n",
    "            invalid_response=False\n",
    "\n",
    "            if RUN_DEBUGGER: \n",
    "                generated_sql, invalid_response, AUDIT_TEXT = SQLDebugger.start_debugger(DATA_SOURCE, generated_sql, user_question, SQLChecker, table_matches, column_matches, AUDIT_TEXT, similar_sql) \n",
    "                # AUDIT_TEXT = AUDIT_TEXT + '\\n Feedback from Debugger: \\n' + feedback_text\n",
    "\n",
    "            final_sql=generated_sql\n",
    "            AUDIT_TEXT = AUDIT_TEXT + \"\\nFinal SQL after Debugger: \\n\" +str(final_sql)\n",
    "\n",
    "\n",
    "    # No matching table found \n",
    "    else:\n",
    "        invalid_response=True\n",
    "        print('No tables found in Vector ...')\n",
    "        AUDIT_TEXT = AUDIT_TEXT + \"\\nNo tables have been found in the Vector DB. The question cannot be answered with the provide data source!\"\n",
    "\n",
    "print(f'\\n\\n AUDIT_TEXT: \\n {AUDIT_TEXT}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not invalid_response:\n",
    "    try: \n",
    "        if EXECUTE_FINAL_SQL is True:\n",
    "                final_exec_result_df=src_connector.retrieve_df(final_sql.replace(\"```sql\",\"\").replace(\"```\",\"\").replace(\"EXPLAIN ANALYZE \",\"\"))\n",
    "                print('\\nQuestion: ' + user_question + '\\n')\n",
    "                # print('\\n Final SQL Execution Result: \\n')\n",
    "                # print(final_exec_result_df)\n",
    "                response = final_exec_result_df\n",
    "                _resp=Responder.run(user_question, response)\n",
    "                AUDIT_TEXT = AUDIT_TEXT + \"\\nModel says \" + str(_resp) \n",
    "\n",
    "\n",
    "        else:  # Do not execute final SQL\n",
    "                print(\"Not executing final SQL since EXECUTE_FINAL_SQL variable is False\\n \")\n",
    "                response = \"Please enable the Execution of the final SQL so I can provide an answer\"\n",
    "                _resp=Responder.run(user_question, response)\n",
    "                AUDIT_TEXT = AUDIT_TEXT + \"\\nModel says \" + str(_resp) \n",
    "\n",
    "    except ValueError: \n",
    "          print('')\n",
    "    # except Exception as e: \n",
    "    #     print(f\"An error occured. Aborting... Error Message: {e}\")\n",
    "        \n",
    "else:  # Do not execute final SQL\n",
    "    print(\"Not executing final SQL as it is invalid, please debug!\")\n",
    "    response = \"I am sorry, I could not come up with a valid SQL.\"\n",
    "    _resp=Responder.run(user_question, response)\n",
    "    AUDIT_TEXT = AUDIT_TEXT + \"\\nModel says \" + str(_resp)\n",
    "\n",
    "print(\"Final Answer:\" + str(_resp))\n",
    "bqconnector.make_audit_entry(DATA_SOURCE, USER_DATABASE, \"gemini-1.0-pro\", user_question, final_sql, found_in_vector, \"\", process_step, \"\", AUDIT_TEXT)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Charts for the results (Run only when you have proper results in the above cells)\n",
    "Agent provides two suggestive google charts to display on a UI with element IDs chart_div and chart_div_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart_js=''\n",
    "chart_js = Visualize.generate_charts(user_question,final_sql,response) #sending \n",
    "# print(chart_js[\"chart_div_1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "html_code = f'''\n",
    "<script type=\"text/javascript\" src=\"https://www.gstatic.com/charts/loader.js\"></script>\n",
    "<script type=\"text/javascript\">\n",
    "{chart_js[\"chart_div\"]}\n",
    "</script>\n",
    "<div id=\"chart_div\"></div>\n",
    "'''\n",
    "\n",
    "HTML(html_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_code = f'''\n",
    "<script type=\"text/javascript\" src=\"https://www.gstatic.com/charts/loader.js\"></script>\n",
    "<script type=\"text/javascript\">\n",
    "{chart_js[\"chart_div_1\"]}\n",
    "</script>\n",
    "<div id=\"chart_div_1\"></div>\n",
    "'''\n",
    "\n",
    "HTML(html_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ—‘ Clean Up Notebook Resources\n",
    "Make sure to delete your Cloud SQL instance and BigQuery Datasets when your are finished with this notebook to avoid further costs. ðŸ’¸ ðŸ’°\n",
    "\n",
    "Uncomment and run the cell below to delete "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # delete Cloud SQL instance\n",
    "# !gcloud sql instances delete {PG_INSTANCE} -q\n",
    "\n",
    "# #delete BigQuery Dataset using bq utility\n",
    "# !bq rm -r -f -d {BQ_DATASET_NAME}\n",
    "\n",
    "# #delete BigQuery 'Open Data QnA' Vector Store Dataset using bq utility\n",
    "\n",
    "# !bq rm -r -f -d {BQ_OPENDATAQNA_DATASET_NAME}\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
