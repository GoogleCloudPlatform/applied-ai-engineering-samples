## ğŸ“¦ **Features** <a name="features"></a>

| Feature                    | Description                                                                                                                    |
| -------------------------- | ------------------------------------------------------------------------------------------------------------------------------ |
| âœ¨ Flexible Data Ingestion | Index data from URLs, Google Cloud Storage (GCS), or pre-indexed datasets.                                                    |
| ğŸ” Multiple Retrieval Methods | Compare Top-K, Multi-Query Retriever, and Contextual Compression Retriever and more.                                                    |
| ğŸ§  LLM Integration       | Utilize different Vertex AI LLM models for answer generation and contextual compression.                                        |
| ğŸ“Š Evaluation             | Evaluate answer quality using Vertex AI's evaluation metrics and user feedback, including automated and human-in-the-loop evaluations. |
| ğŸ–¥ï¸ Streamlit Frontend     | Intuitive UI for querying, configuring experiments, visualizing results, and providing user feedback.                         |
| â˜ï¸ Scalable Deployment | Deploy backend services as serverless on Cloud Functions for scalability, cost-efficiency, and ease of management.                            |
| ğŸ”„ Data Processing Pipeline | Modular and scalable data ingestion and processing pipeline built with Apache Beam running on Cloud Dataflow (Apache Beam). Supports different data loaders, splitters, and vector stores. |
| âš™ï¸ Orchestration | Flexible experiment configuration and management with Cloud Workflows, to orchestrate concurrent and parallel execution of RAG tasks.                 |